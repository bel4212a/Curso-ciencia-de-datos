{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paralelizacion de entrenamiento de redes neuronales con TensorFlow\n",
    "\n",
    "En esta seccion dejaremos atras los rudimentos de las matematicas y nos centraremos en utilizar TensorFlow, la cual es una de las librerias mas populares de arpendizaje profundo y que realiza una implementacion mas eficaz de las redes neuronales que cualquier otra implementacion de Numpy.\n",
    "\n",
    "TensorFlow es una interfaz de programacion multiplataforma y escalable para implementar y ejecutar algortimos de aprendizaje automatico de una manera mas eficaz ya que permite usar tanto la CPU como la GPU, la cual suele tener muchos mas procesadores que la CPU, los cuales, combinando sus frecuencias, presentan un rendimiento mas potente. La API mas desarrollada de esta herramienta se presenta para Python, por lo cual muchos desarrolladores se ven atraidos a este lenguaje.\n",
    "\n",
    "## Primeros pasos con TensorFlow\n",
    "\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/02.01-understanding-data-types.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:37:42.144677Z",
     "start_time": "2021-03-15T23:37:35.224942Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creando tensores\n",
    "# =============================================\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "a = np.array([1, 2, 3], dtype=np.int32)\n",
    "b = [4, 5, 6]\n",
    "\n",
    "t_a = tf.convert_to_tensor(a)\n",
    "t_b = tf.convert_to_tensor(b)\n",
    "\n",
    "print(t_a)\n",
    "print(t_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:39:40.542083Z",
     "start_time": "2021-03-15T23:39:40.478254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obteniendo las dimensiones de un tensor\n",
    "# ===============================================\n",
    "t_ones = tf.ones((2, 3))\n",
    "print(t_ones)\n",
    "t_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:41:01.011035Z",
     "start_time": "2021-03-15T23:41:01.002060Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obteniendo los valores del tensor como array\n",
    "# ===============================================\n",
    "t_ones.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:42:12.474932Z",
     "start_time": "2021-03-15T23:42:12.458975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creando un tensor de valores constantes\n",
    "# ================================================\n",
    "const_tensor = tf.constant([1.2, 5, np.pi], dtype=tf.float32)\n",
    "print(const_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:42:42.220775Z",
     "start_time": "2021-03-15T23:42:42.201830Z"
    }
   },
   "outputs": [],
   "source": [
    "matriz = np.array([[2, 3, 4, 5], [6, 7, 8, 8]], dtype = np.int32)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:42:55.297264Z",
     "start_time": "2021-03-15T23:42:55.280309Z"
    }
   },
   "outputs": [],
   "source": [
    "matriz_tf = tf.convert_to_tensor(matriz)\n",
    "print(matriz_tf, end = '\\n'*2)\n",
    "print(matriz_tf.numpy(), end = '\\n'*2)\n",
    "print(matriz_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulando los tipos de datos y forma de un tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:44:25.200244Z",
     "start_time": "2021-03-15T23:44:25.192255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cambiando el tipo de datos del tensor\n",
    "# ==============================================\n",
    "print(matriz_tf.dtype)\n",
    "\n",
    "matriz_tf_n = tf.cast(matriz_tf, tf.int64)\n",
    "\n",
    "print(matriz_tf_n.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:45:57.113934Z",
     "start_time": "2021-03-15T23:45:57.074047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transponiendo un tensor\n",
    "# =================================================\n",
    "t = tf.random.uniform(shape=(3, 5))\n",
    "print(t, end = '\\n'*2)\n",
    "\n",
    "t_tr = tf.transpose(t)\n",
    "print(t_tr, end = '\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:47:01.970944Z",
     "start_time": "2021-03-15T23:47:01.939066Z"
    }
   },
   "outputs": [],
   "source": [
    "# Redimensionando un vector\n",
    "# =====================================\n",
    "t = tf.zeros((30,))\n",
    "print(t, end = '\\n'*2)\n",
    "print(t.shape, end = '\\n'*3)\n",
    "\n",
    "t_reshape = tf.reshape(t, shape=(5, 6))\n",
    "print(t_reshape, end = '\\n'*2)\n",
    "print(t_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:48:33.023817Z",
     "start_time": "2021-03-15T23:48:32.991908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removiendo las dimensiones innecesarias\n",
    "# =====================================================\n",
    "t = tf.zeros((1, 2, 1, 4, 1))\n",
    "print(t, end = '\\n'*2)\n",
    "print(t.shape, end = '\\n'*3)\n",
    "\n",
    "t_sqz = tf.squeeze(t, axis=(2, 4))\n",
    "print(t_sqz, end = '\\n'*2)\n",
    "print(t_sqz.shape, end = '\\n'*3)\n",
    "print(t.shape, ' --> ', t_sqz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones matematicas sobre tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:56:14.123880Z",
     "start_time": "2021-03-15T23:56:14.082995Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inicializando dos tensores con numeros aleatorios\n",
    "# =============================================================\n",
    "tf.random.set_seed(1)\n",
    "t1 = tf.random.uniform(shape=(5, 2), minval=-1.0, maxval=1.0)\n",
    "t2 = tf.random.normal(shape=(5, 2), mean=0.0, stddev=1.0)\n",
    "\n",
    "print(t1, '\\n'*2, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T23:58:31.346518Z",
     "start_time": "2021-03-15T23:58:31.324569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Producto tipo element-wise: elemento a elemento\n",
    "# =================================================\n",
    "t3 = tf.multiply(t1, t2).numpy()\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:01:04.631720Z",
     "start_time": "2021-03-16T00:01:04.591835Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Promedio segun el eje\n",
    "# ================================================\n",
    "t4 = tf.math.reduce_mean(t1, axis=None)\n",
    "print(t4, end = '\\n'*3)\n",
    "\n",
    "t4 = tf.math.reduce_mean(t1, axis=0)\n",
    "print(t4, end = '\\n'*3)\n",
    "\n",
    "t4 = tf.math.reduce_mean(t1, axis=1)\n",
    "print(t4, end = '\\n'*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:02:54.929455Z",
     "start_time": "2021-03-16T00:02:54.892553Z"
    }
   },
   "outputs": [],
   "source": [
    "# suma segun el eje\n",
    "# =================================================\n",
    "t4 = tf.math.reduce_sum(t1, axis=None)\n",
    "print('Suma de todos los elementos:', t4, end = '\\n'*3)\n",
    "\n",
    "t4 = tf.math.reduce_sum(t1, axis=0)\n",
    "print('Suma de los elementos por columnas:', t4, end = '\\n'*3)\n",
    "\n",
    "t4 = tf.math.reduce_sum(t1, axis=1)\n",
    "print('Suma de los elementos por filas:', t4, end = '\\n'*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:03:43.618121Z",
     "start_time": "2021-03-16T00:03:43.573241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Desviacion estandar segun el eje\n",
    "# =================================================\n",
    "t4 = tf.math.reduce_std(t1, axis=None)\n",
    "print('Suma de todos los elementos:', t4, end = '\\n'*3)\n",
    "\n",
    "t4 = tf.math.reduce_std(t1, axis=0)\n",
    "print('Suma de los elementos por columnas:', t4, end = '\\n'*3)\n",
    "\n",
    "t4 = tf.math.reduce_std(t1, axis=1)\n",
    "print('Suma de los elementos por filas:', t4, end = '\\n'*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:06:44.436432Z",
     "start_time": "2021-03-16T00:06:44.379787Z"
    }
   },
   "outputs": [],
   "source": [
    "# Producto entre matrices\n",
    "# ===========================================\n",
    "t5 = tf.linalg.matmul(t1, t2, transpose_b=True)\n",
    "print(t5.numpy(), end = '\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:07:08.663761Z",
     "start_time": "2021-03-16T00:07:08.653791Z"
    }
   },
   "outputs": [],
   "source": [
    "# Producto entre matrices\n",
    "# ===========================================\n",
    "t6 = tf.linalg.matmul(t1, t2, transpose_a=True)\n",
    "print(t6.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:09:20.850405Z",
     "start_time": "2021-03-16T00:09:20.824477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculando la norma de un vector\n",
    "# ==========================================\n",
    "norm_t1 = tf.norm(t1, ord=2, axis=None).numpy()\n",
    "print(norm_t1, end='\\n'*2)\n",
    "\n",
    "norm_t1 = tf.norm(t1, ord=2, axis=0).numpy()\n",
    "print(norm_t1, end='\\n'*2)\n",
    "\n",
    "norm_t1 = tf.norm(t1, ord=2, axis=1).numpy()\n",
    "print(norm_t1, end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partir, apilar y concatenar tensores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:10:48.083745Z",
     "start_time": "2021-03-16T00:10:48.061288Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datos a trabajar\n",
    "# =======================================\n",
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((6,))\n",
    "print(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:11:44.953807Z",
     "start_time": "2021-03-16T00:11:44.926886Z"
    }
   },
   "outputs": [],
   "source": [
    "# Partiendo el tensor en un numero determinado de piezas\n",
    "# ======================================================\n",
    "t_splits = tf.split(t, num_or_size_splits = 3)\n",
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:12:52.803113Z",
     "start_time": "2021-03-16T00:12:52.772195Z"
    }
   },
   "outputs": [],
   "source": [
    "# Partiendo el tensor segun los tama√±os definidos\n",
    "# ======================================================\n",
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((6,))\n",
    "print(t.numpy())\n",
    "t_splits = tf.split(t, num_or_size_splits=[3, 3])\n",
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:13:05.146994Z",
     "start_time": "2021-03-16T00:13:05.113094Z"
    }
   },
   "outputs": [],
   "source": [
    "print(matriz_tf.numpy())\n",
    "# m_splits = tf.split(t, num_or_size_splits = 0, axis = 1)\n",
    "matriz_n = tf.reshape(matriz_tf, shape = (8,))\n",
    "print(matriz_n.numpy())\n",
    "m_splits = tf.split(matriz_n, num_or_size_splits = 2)\n",
    "[item.numpy() for item in m_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:14:28.679268Z",
     "start_time": "2021-03-16T00:14:28.649348Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenando tensores\n",
    "# =========================================\n",
    "A = tf.ones((3,))\n",
    "print(A, end ='\\n'*2)\n",
    "\n",
    "B = tf.zeros((2,))\n",
    "print(B, end ='\\n'*2)\n",
    "\n",
    "C = tf.concat([A, B], axis=0)\n",
    "print(C.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:15:47.452207Z",
     "start_time": "2021-03-16T00:15:47.420298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apilando tensores\n",
    "# =========================================\n",
    "A = tf.ones((3,))\n",
    "print(A, end ='\\n'*2)\n",
    "B = tf.zeros((3,))\n",
    "print(B, end ='\\n'*2)\n",
    "S = tf.stack([A, B], axis=1)\n",
    "print(S.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas funciones y herramientas en:\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"burk\">\n",
    "EJERCICIOS</div><i class=\"fa fa-lightbulb-o \"></i>\n",
    "\n",
    "1. Cree dos tensores de dimensiones (4, 6), de numeros aleatorios provenientes de una distribucion normal estandar con promedio 0.0 y dsv 1.0. Imprimalos.\n",
    "2. Multiplique los anteriores tensores de las dos formas vistas, element-wise y producto matricial, realizando las dos transposiciones vistas. \n",
    "3. Calcule los promedios, desviaciones estandar y suma de sus elementos para los dos tensores.\n",
    "4. Redimensione los tensores para que sean ahora de rango 1.\n",
    "5. Calcule el coseno de los elementos de  los tensores (revise la documentacion).\n",
    "6. Cree un tensor de rango 1 con 1001 elementos, empezando con el 0 y hasta el 30.\n",
    "7. Realice un for sobre los elementos del tensor e imprimalos.\n",
    "8. Realice el calculo de los factoriales de los numero del 1 al 30 usando el tensor del punto 6. Imprima el resultado como un DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:08:27.899080Z",
     "start_time": "2021-03-14T23:08:27.880131Z"
    }
   },
   "source": [
    "# Creaci√≥n de *pipelines* de entrada con tf.data: la API de conjunto de datos de TensorFlow\n",
    "\n",
    "Cuando entrenamos un modelo NN profundo, generalmente entrenamos el modelo de forma incremental utilizando un algoritmo de optimizaci√≥n iterativo como el descenso de gradiente estoc√°stico, como hemos visto en clases anteriores.\n",
    "\n",
    "La API de Keras es un contenedor de TensorFlow para crear modelos NN. La API de Keras proporciona un m√©todo, `.fit ()`, para entrenar los modelos. En los casos en que el conjunto de datos de entrenamiento es bastante peque√±o y se puede cargar como un tensor en la memoria, los modelos de TensorFlow (que se compilan con la API de Keras) pueden usar este tensor directamente a trav√©s de su m√©todo .fit () para el entrenamiento. Sin embargo, en casos de uso t√≠picos, cuando el conjunto de datos es demasiado grande para caber en la memoria de la computadora, necesitaremos cargar los datos del dispositivo de almacenamiento principal (por ejemplo, el disco duro o la unidad de estado s√≥lido) en trozos, es decir, lote por lote. \n",
    "\n",
    "Adem√°s, es posible que necesitemos construir un *pipeline* de procesamiento de datos para aplicar ciertas transformaciones y pasos de preprocesamiento a nuestros datos, como el centrado medio, el escalado o la adici√≥n de ruido para aumentar el procedimiento de entrenamiento y evitar el sobreajuste.\n",
    "\n",
    "Aplicar las funciones de preprocesamiento manualmente cada vez puede resultar bastante engorroso. Afortunadamente, TensorFlow proporciona una clase especial para construir *pipelines* de preprocesamiento eficientes y convenientes. En esta parte, veremos una descripci√≥n general de los diferentes m√©todos para construir un conjunto de datos de TensorFlow, incluidas las transformaciones del conjunto de datos y los pasos de preprocesamiento comunes.\n",
    "\n",
    "## Creando un Dataset de TensorFlow desde tensores existentes\n",
    "\n",
    "Si los datos ya existen en forma de un objeto tensor, una lista de Python o una matriz NumPy, podemos crear f√°cilmente un conjunto de datos usando la funci√≥n `tf.data.Dataset.from_tensor_slices()`. Esta funci√≥n devuelve un objeto de la clase Dataset, que podemos usar para iterar a trav√©s de los elementos individuales en el conjunto de datos de entrada:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T23:25:30.539885Z",
     "start_time": "2021-03-16T23:25:21.710079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Ejemplo con listas\n",
    "# ======================================================\n",
    "a = [1.2, 3.4, 7.5, 4.1, 5.0, 1.0]\n",
    "ds = tf.data.Dataset.from_tensor_slices(a)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T23:28:00.791323Z",
     "start_time": "2021-03-16T23:28:00.772316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4, shape=(), dtype=float32)\n",
      "tf.Tensor(7.5, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "1.2\n",
      "3.4\n",
      "7.5\n",
      "4.1\n",
      "5.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for item in ds:\n",
    "    print(item)\n",
    "    \n",
    "for i in ds:\n",
    "    print(i.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos crear lotes a partir de este conjunto de datos, con un tama√±o de lote deseado de 3, podemos hacerlo de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T23:30:43.198156Z",
     "start_time": "2021-03-16T23:30:43.174418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1: tf.Tensor([1.2 3.4 7.5], shape=(3,), dtype=float32)\n",
      "batch 2: tf.Tensor([4.1 5.  1. ], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Creando lotes de 3 elementos cada uno\n",
    "# ===================================================\n",
    "ds_batch = ds.batch(3)\n",
    "for i, elem in enumerate(ds_batch, 1):\n",
    "    print(f'batch {i}:', elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto crear√° dos lotes a partir de este conjunto de datos, donde los primeros tres elementos van al lote n¬∞ 1 y los elementos restantes al lote n¬∞ 2. El m√©todo `.batch()` tiene un argumento opcional, `drop_remainder`, que es √∫til para los casos en los que el n√∫mero de elementos en el tensor no es divisible por el tama√±o de lote deseado. El valor predeterminado de `drop_remainder` es `False`.\n",
    "\n",
    "## Combinar dos tensores en un Dataset\n",
    "\n",
    "A menudo, podemos tener los datos en dos (o posiblemente m√°s) tensores. Por ejemplo, podr√≠amos tener un tensor para caracter√≠sticas y un tensor para etiquetas. En tales casos, necesitamos construir un conjunto de datos que combine estos tensores juntos, lo que nos permitir√° recuperar los elementos de estos tensores en tuplas.\n",
    "\n",
    "Suponga que tenemos dos tensores, t_x y t_y. El tensor t_x contiene nuestros valores de caracter√≠sticas, cada uno de tama√±o 3, y t_y almacena las etiquetas de clase. Para este ejemplo, primero creamos estos dos tensores de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T23:32:04.012039Z",
     "start_time": "2021-03-16T23:32:03.986966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.16513085 0.9014813  0.6309742 ]\n",
      " [0.4345461  0.29193902 0.64250207]\n",
      " [0.9757855  0.43509948 0.6601019 ]\n",
      " [0.60489583 0.6366315  0.6144488 ]], shape=(4, 3), dtype=float32)\n",
      "tf.Tensor([0 1 2 3], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Datos de ejemplo\n",
    "# ============================================\n",
    "tf.random.set_seed(1)\n",
    "t_x = tf.random.uniform([4, 3], dtype=tf.float32)\n",
    "t_y = tf.range(4)\n",
    "print(t_x)\n",
    "print(t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T23:33:23.478517Z",
     "start_time": "2021-03-16T23:33:23.437464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.16513085 0.9014813  0.6309742 ]  y: 0\n",
      "x: [0.4345461  0.29193902 0.64250207]  y: 1\n",
      "x: [0.9757855  0.43509948 0.6601019 ]  y: 2\n",
      "x: [0.60489583 0.6366315  0.6144488 ]  y: 3\n"
     ]
    }
   ],
   "source": [
    "# Uniendo los dos tensores en un Dataset\n",
    "# ============================================\n",
    "ds_x = tf.data.Dataset.from_tensor_slices(t_x)\n",
    "ds_y = tf.data.Dataset.from_tensor_slices(t_y)\n",
    "\n",
    "ds_joint = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "\n",
    "for example in ds_joint:\n",
    "    print('x:', example[0].numpy(),' y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T23:34:24.551211Z",
     "start_time": "2021-03-16T23:34:24.505128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.16513085 0.9014813  0.6309742 ]  y: 0\n",
      "x: [0.4345461  0.29193902 0.64250207]  y: 1\n",
      "x: [0.9757855  0.43509948 0.6601019 ]  y: 2\n",
      "x: [0.60489583 0.6366315  0.6144488 ]  y: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((3,), ()), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_joint = tf.data.Dataset.from_tensor_slices((t_x, t_y))\n",
    "for example in ds_joint:\n",
    "    #print(example)\n",
    "    print('x:', example[0].numpy(), ' y:', example[1].numpy())\n",
    "\n",
    "ds_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T23:36:24.488807Z",
     "start_time": "2021-03-16T23:36:24.227413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: [-0.6697383   0.80296254  0.26194835]  y: 0\n",
      " x: [-0.13090777 -0.41612196  0.28500414]  y: 1\n",
      " x: [ 0.951571   -0.12980103  0.32020378]  y: 2\n",
      " x: [0.20979166 0.27326298 0.22889757]  y: 3\n"
     ]
    }
   ],
   "source": [
    "# Operacion sobre el dataset generado\n",
    "# ====================================================\n",
    "ds_trans = ds_joint.map(lambda x, y: (x*2-1.0, y))\n",
    "for example in ds_trans: \n",
    "    print(' x:', example[0].numpy(), ' y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mezclar, agrupar y repetir\n",
    "\n",
    "Para entrenar un modelo NN usando la optimizaci√≥n de descenso de gradiente estoc√°stico, es importante alimentar los datos de entrenamiento como lotes mezclados aleatoriamente. Ya hemos visto arriba como crear lotes llamando al m√©todo `.batch()` de un objeto de conjunto de datos. Ahora, adem√°s de crear lotes, vamos a mezclar y reiterar sobre los conjuntos de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:26:45.009397Z",
     "start_time": "2021-03-16T00:26:44.949611Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mezclando los elementos de un tensor\n",
    "# ===================================================\n",
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.shuffle(buffer_size = len(t_x))\n",
    "for example in ds:\n",
    "    print(' x:', example[0].numpy(), ' y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:21:23.036313Z",
     "start_time": "2021-03-15T22:21:23.025308Z"
    }
   },
   "source": [
    "donde las filas se barajan sin perder la correspondencia uno a uno entre las entradas en x e y. El m√©todo `.shuffle()` requiere un argumento llamado `buffer_size`, que determina cu√°ntos elementos del conjunto de datos se agrupan antes de barajar. Los elementos del b√∫fer se recuperan aleatoriamente y su lugar en el b√∫fer se asigna a los siguientes elementos del conjunto de datos original (sin mezclar). Por lo tanto, si elegimos un tama√±o de b√∫fer peque√±o, es posible que no mezclemos perfectamente el conjunto de datos.\n",
    "\n",
    "Si el conjunto de datos es peque√±o, la elecci√≥n de un tama√±o de b√∫fer relativamente peque√±o puede afectar negativamente el rendimiento predictivo del NN, ya que es posible que el conjunto de datos no est√© completamente aleatorizado. En la pr√°ctica, sin embargo, por lo general no tiene un efecto notable cuando se trabaja con conjuntos de datos relativamente grandes, lo cual es com√∫n en el aprendizaje profundo.\n",
    "\n",
    "Alternativamente, para asegurar una aleatorizaci√≥n completa durante cada √©poca, simplemente podemos elegir un tama√±o de b√∫fer que sea igual al n√∫mero de ejemplos de entrenamiento, como en el c√≥digo anterior (`buffer_size = len(t_x)`).\n",
    "\n",
    " Ahora, creemos lotes a partir del conjunto de datos ds_joint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:26:47.795112Z",
     "start_time": "2021-03-16T00:26:47.776161Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = ds_joint.batch(batch_size = 3, drop_remainder = False)\n",
    "print(ds)\n",
    "batch_x, batch_y = next(iter(ds))\n",
    "print('Batch-x:\\n', batch_x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:26:50.218322Z",
     "start_time": "2021-03-16T00:26:50.213336Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Batch-y: ', batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adem√°s, al entrenar un modelo para m√∫ltiples √©pocas, necesitamos mezclar e iterar sobre el conjunto de datos por el n√∫mero deseado de √©pocas. Entonces, repitamos el conjunto de datos por lotes dos veces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:26:51.953195Z",
     "start_time": "2021-03-16T00:26:51.924314Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = ds_joint.batch(3).repeat(count = 2)\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.numpy(), batch_y.numpy(), end = '\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto da como resultado dos copias de cada lote. Si cambiamos el orden de estas dos operaciones, es decir, primero lote y luego repetimos, los resultados ser√°n diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:26:53.682413Z",
     "start_time": "2021-03-16T00:26:53.656484Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "ds = ds_joint.repeat(count=2).batch(3)\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.numpy(), batch_y.numpy(), end = '\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, para comprender mejor c√≥mo se comportan estas tres operaciones (batch, shuffle y repeat), experimentemos con ellas en diferentes √≥rdenes. Primero, combinaremos las operaciones en el siguiente orden: (1) shuffle, (2) batch y (3) repeat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:27:15.728820Z",
     "start_time": "2021-03-16T00:27:15.696905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Orden 1: shuffle -> batch -> repeat\n",
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.shuffle(4).batch(2).repeat(3)\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x, batch_y.numpy(), end = '\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:28:07.074667Z",
     "start_time": "2021-03-16T00:28:07.037771Z"
    }
   },
   "outputs": [],
   "source": [
    "# Orden 2: batch -> shuffle -> repeat\n",
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.batch(2).shuffle(4).repeat(3)\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x, batch_y.numpy(), end = '\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T00:29:12.495520Z",
     "start_time": "2021-03-16T00:29:12.468561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Orden 2: batch -> repeat-> shuffle\n",
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.batch(2).repeat(3).shuffle(4)\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x, batch_y.numpy(), end = '\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obteniendo conjuntos de datos disponibles de la biblioteca tensorflow_datasets\n",
    "\n",
    "La biblioteca tensorflow_datasets proporciona una buena colecci√≥n de conjuntos de datos disponibles gratuitamente para entrenar o evaluar modelos de aprendizaje profundo. Los conjuntos de datos est√°n bien formateados y vienen con descripciones informativas, incluido el formato de caracter√≠sticas y etiquetas y su tipo y dimensionalidad, as√≠ como la cita del documento original que introdujo el conjunto de datos en formato BibTeX. Otra ventaja es que todos estos conjuntos de datos est√°n preparados y listos para usar como objetos tf.data.Dataset, por lo que todas las funciones que cubrimos se pueden usar directamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T01:14:38.389028Z",
     "start_time": "2021-03-16T01:14:38.381057Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T01:15:00.029816Z",
     "start_time": "2021-03-16T01:14:58.075170Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print(len(tfds.list_builders()))\n",
    "print(tfds.list_builders()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T01:37:44.489390Z",
     "start_time": "2021-03-16T01:37:00.769967Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Trabajando con el archivo mnist\n",
    "# ===============================================\n",
    "mnist, mnist_info = tfds.load('mnist', with_info=True, shuffle_files=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T01:38:39.615198Z",
     "start_time": "2021-03-16T01:38:39.607275Z"
    }
   },
   "outputs": [],
   "source": [
    "print(mnist_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T01:39:08.811745Z",
     "start_time": "2021-03-16T01:39:08.806758Z"
    }
   },
   "outputs": [],
   "source": [
    "print(mnist.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T01:45:32.485050Z",
     "start_time": "2021-03-16T01:45:32.420194Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_train = mnist['train']\n",
    "ds_train = ds_train.map(lambda item:(item['image'], item['label']))\n",
    "ds_train = ds_train.batch(10)\n",
    "batch = next(iter(ds_train))\n",
    "print(batch[0].shape, batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T01:43:19.450046Z",
     "start_time": "2021-03-16T01:43:19.062807Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i,(image,label) in enumerate(zip(batch[0], batch[1])):\n",
    "    ax = fig.add_subplot(2, 5, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(image[:, :, 0], cmap='gray_r')\n",
    "    ax.set_title('{}'.format(label), size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T01:32:59.052286Z",
     "start_time": "2021-03-16T01:32:59.030346Z"
    }
   },
   "source": [
    "# Construyendo un modelo NN en TensorFlow\n",
    "\n",
    "## La API de TensorFlow Keras (tf.keras)\n",
    "\n",
    "Keras es una API NN de alto nivel y se desarroll√≥ originalmente para ejecutarse sobre otras bibliotecas como TensorFlow y Theano. Keras proporciona una interfaz de programaci√≥n modular y f√°cil de usar que permite la creaci√≥n de prototipos y la construcci√≥n de modelos complejos en solo unas pocas l√≠neas de c√≥digo. Keras se puede instalar independientemente de PyPI y luego configurarse para usar TensorFlow como su motor de backend. Keras est√° estrechamente integrado en TensorFlow y se puede acceder a sus m√≥dulos a trav√©s de tf.keras.\n",
    "\n",
    "En TensorFlow 2.0, tf.keras se ha convertido en el enfoque principal y recomendado para implementar modelos. Esto tiene la ventaja de que admite funcionalidades espec√≠ficas de TensorFlow, como las canalizaciones de conjuntos de datos que usan tf.data.\n",
    "\n",
    "La API de Keras (tf.keras) hace que la construcci√≥n de un modelo NN sea extremadamente f√°cil. El enfoque m√°s utilizado para crear una NN en TensorFlow es a trav√©s de `tf.keras.Sequential()`, que permite apilar capas para formar una red. Se puede dar una pila de capas en una lista de Python a un modelo definido como tf.keras.Sequential(). Alternativamente, las capas se pueden agregar una por una usando el m√©todo .add().\n",
    "\n",
    "Adem√°s, tf.keras nos permite definir un modelo subclasificando tf.keras.Model.\n",
    "\n",
    "Esto nos da m√°s control sobre la propagacion hacia adelante al definir el m√©todo call() para nuestra clase modelo para especificar la propagacion hacia adelante explicitamente. \n",
    "\n",
    "Finalmente, los modelos construidos usando la API tf.keras se pueden compilar y entrenar a trav√©s de los m√©todos .compile() y .fit()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo  un modelo de regresion lineal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T21:22:33.313085Z",
     "start_time": "2021-03-16T21:22:33.308345Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.arange(10).reshape((10, 1))\n",
    "y_train = np.array([1.0, 1.3, 3.1, 2.0, 5.0, 6.3, 6.6, 7.4, 8.0, 9.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T21:22:52.304374Z",
     "start_time": "2021-03-16T21:22:52.299521Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T21:23:35.006693Z",
     "start_time": "2021-03-16T21:23:34.325166Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X_train, y_train, 'o', markersize=10)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T21:26:30.488706Z",
     "start_time": "2021-03-16T21:26:30.472738Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_train_norm = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "ds_train_orig = tf.data.Dataset.from_tensor_slices((tf.cast(X_train_norm, tf.float32),tf.cast(y_train, tf.float32)))\n",
    "\n",
    "for i in ds_train_orig:\n",
    "    print(i[0].numpy(), i[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos definir nuestro modelo de regresi√≥n lineal como $ùëß = ùë§x + ùëè$. Aqu√≠, vamos a utilizar la API de Keras. `tf.keras` proporciona capas predefinidas para construir modelos NN complejos, pero para empezar, usaremos un modelo desde cero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T21:31:02.993466Z",
     "start_time": "2021-03-16T21:31:02.988829Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.w = tf.Variable(0.0, name='weight')\n",
    "        self.b = tf.Variable(0.0, name='bias')\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.w * x + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T21:31:34.590016Z",
     "start_time": "2021-03-16T21:31:34.549185Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "model.build(input_shape=(None, 1))\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
