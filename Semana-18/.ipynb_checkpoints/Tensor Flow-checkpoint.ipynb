{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paralelizacion de entrenamiento de redes neuronales con TensorFlow\n",
    "\n",
    "En esta seccion dejaremos atras los rudimentos de las matematicas y nos centraremos en utilizar TensorFlow, la cual es una de las librerias mas populares de arpendizaje profundo y que realiza una implementacion mas eficaz de las redes neuronales que cualquier otra implementacion de Numpy.\n",
    "\n",
    "TensorFlow es una interfaz de programacion multiplataforma y escalable para implementar y ejecutar algortimos de aprendizaje automatico de una manera mas eficaz ya que permite usar tanto la CPU como la GPU, la cual suele tener muchos mas procesadores que la CPU, los cuales, combinando sus frecuencias, presentan un rendimiento mas potente. La API mas desarrollada de esta herramienta se presenta para Python, por lo cual muchos desarrolladores se ven atraidos a este lenguaje.\n",
    "\n",
    "## Primeros pasos con TensorFlow\n",
    "\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/02.01-understanding-data-types.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:07:12.284904Z",
     "start_time": "2021-03-15T22:07:08.796841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Creando tensores\n",
    "# =============================================\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "a = np.array([1, 2, 3], dtype=np.int32)\n",
    "b = [4, 5, 6]\n",
    "\n",
    "t_a = tf.convert_to_tensor(a)\n",
    "t_b = tf.convert_to_tensor(b)\n",
    "\n",
    "print(t_a)\n",
    "print(t_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:09:31.597447Z",
     "start_time": "2021-03-15T22:09:31.580492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obteniendo las dimensiones de un tensor\n",
    "# ===============================================\n",
    "t_ones = tf.ones((2, 3))\n",
    "print(t_ones)\n",
    "t_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:10:03.539259Z",
     "start_time": "2021-03-15T22:10:03.524308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obteniendo los valores del tensor como array\n",
    "# ===============================================\n",
    "t_ones.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:10:39.848497Z",
     "start_time": "2021-03-15T22:10:39.837569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.2   5.    3.142], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Creando un tensor de valores constantes\n",
    "# ================================================\n",
    "const_tensor = tf.constant([1.2, 5, np.pi], dtype=tf.float32)\n",
    "print(const_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:10:59.014033Z",
     "start_time": "2021-03-15T22:10:58.997118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 4, 5],\n",
       "       [6, 7, 8, 8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz = np.array([[2, 3, 4, 5], [6, 7, 8, 8]], dtype = np.int32)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:11:09.182621Z",
     "start_time": "2021-03-15T22:11:09.172339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3 4 5]\n",
      " [6 7 8 8]], shape=(2, 4), dtype=int32)\n",
      "\n",
      "[[2 3 4 5]\n",
      " [6 7 8 8]]\n",
      "\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "matriz_tf = tf.convert_to_tensor(matriz)\n",
    "print(matriz_tf, end = '\\n'*2)\n",
    "print(matriz_tf.numpy(), end = '\\n'*2)\n",
    "print(matriz_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulando los tipos de datos y forma de un tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T21:29:05.599199Z",
     "start_time": "2021-03-14T21:29:05.595203Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cambiando el tipo de datos del tensor\n",
    "# ==============================================\n",
    "print(matriz_tf.dtype)\n",
    "\n",
    "matriz_tf_n = tf.cast(matriz_tf, tf.int64)\n",
    "\n",
    "print(matriz_tf_n.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T21:31:28.204004Z",
     "start_time": "2021-03-14T21:31:28.197023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transponiendo un tensor\n",
    "# =================================================\n",
    "t = tf.random.uniform(shape=(3, 5))\n",
    "print(t, end = '\\n'*2)\n",
    "\n",
    "t_tr = tf.transpose(t)\n",
    "print(t_tr, end = '\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T21:33:44.814706Z",
     "start_time": "2021-03-14T21:33:44.807718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Redimensionando un vector\n",
    "# =====================================\n",
    "t = tf.zeros((30,))\n",
    "print(t, end = '\\n'*2)\n",
    "print(t.shape, end = '\\n'*3)\n",
    "\n",
    "t_reshape = tf.reshape(t, shape=(5, 6))\n",
    "print(t_reshape, end = '\\n'*2)\n",
    "print(t_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T21:35:34.268244Z",
     "start_time": "2021-03-14T21:35:34.262213Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removiendo las dimensiones innecesarias\n",
    "# =====================================================\n",
    "t = tf.zeros((1, 2, 1, 4, 1))\n",
    "print(t, end = '\\n'*2)\n",
    "print(t.shape, end = '\\n'*3)\n",
    "\n",
    "t_sqz = tf.squeeze(t, axis=(2, 4))\n",
    "print(t_sqz, end = '\\n'*2)\n",
    "print(t_sqz.shape, end = '\\n'*3)\n",
    "print(t.shape, ' --> ', t_sqz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones matematicas sobre tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T21:39:05.885707Z",
     "start_time": "2021-03-14T21:39:05.877711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inicializando dos tensores con numeros aleatorios\n",
    "# =============================================================\n",
    "tf.random.set_seed(1)\n",
    "t1 = tf.random.uniform(shape=(5, 2), minval=-1.0, maxval=1.0)\n",
    "t2 = tf.random.normal(shape=(5, 2), mean=0.0, stddev=1.0)\n",
    "\n",
    "print(t1, '\\n'*2, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T21:40:04.074125Z",
     "start_time": "2021-03-14T21:40:04.069166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Producto tipo element-wise: elemento a elemento\n",
    "# =================================================\n",
    "t3 = tf.multiply(t1, t2).numpy()\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T21:43:04.129154Z",
     "start_time": "2021-03-14T21:43:04.122172Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Promedio segun el eje\n",
    "# ================================================\n",
    "t4 = tf.math.reduce_mean(t1, axis=None)\n",
    "print(t4, end = '\\n'*3)\n",
    "\n",
    "t4 = tf.math.reduce_mean(t1, axis=0)\n",
    "print(t4, end = '\\n'*3)\n",
    "\n",
    "t4 = tf.math.reduce_mean(t1, axis=1)\n",
    "print(t4, end = '\\n'*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T21:45:32.252390Z",
     "start_time": "2021-03-14T21:45:32.245381Z"
    }
   },
   "outputs": [],
   "source": [
    "# suma segun el eje\n",
    "# =================================================\n",
    "t4 = tf.math.reduce_sum(t1, axis=None)\n",
    "print('Suma de todos los elementos:', t4, end = '\\n'*3)\n",
    "\n",
    "t4 = tf.math.reduce_sum(t1, axis=0)\n",
    "print('Suma de los elementos por columnas:', t4, end = '\\n'*3)\n",
    "\n",
    "t4 = tf.math.reduce_sum(t1, axis=1)\n",
    "print('Suma de los elementos por filas:', t4, end = '\\n'*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T21:46:46.730612Z",
     "start_time": "2021-03-14T21:46:46.721635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Desviacion estandar segun el eje\n",
    "# =================================================\n",
    "t4 = tf.math.reduce_std(t1, axis=None)\n",
    "print('Suma de todos los elementos:', t4, end = '\\n'*3)\n",
    "\n",
    "t4 = tf.math.reduce_std(t1, axis=0)\n",
    "print('Suma de los elementos por columnas:', t4, end = '\\n'*3)\n",
    "\n",
    "t4 = tf.math.reduce_std(t1, axis=1)\n",
    "print('Suma de los elementos por filas:', t4, end = '\\n'*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T21:50:47.293069Z",
     "start_time": "2021-03-14T21:50:47.288083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Producto entre matrices\n",
    "# ===========================================\n",
    "t5 = tf.linalg.matmul(t1, t2, transpose_b=True)\n",
    "print(t5.numpy(), end = '\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T21:56:01.507392Z",
     "start_time": "2021-03-14T21:56:01.501408Z"
    }
   },
   "outputs": [],
   "source": [
    "# Producto entre matrices\n",
    "# ===========================================\n",
    "t6 = tf.linalg.matmul(t1, t2, transpose_a=True)\n",
    "print(t6.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T21:59:23.550095Z",
     "start_time": "2021-03-14T21:59:23.540122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculando la norma de un vector\n",
    "# ==========================================\n",
    "norm_t1 = tf.norm(t1, ord=2, axis=None).numpy()\n",
    "print(norm_t1, end='\\n'*2)\n",
    "\n",
    "norm_t1 = tf.norm(t1, ord=2, axis=0).numpy()\n",
    "print(norm_t1, end='\\n'*2)\n",
    "\n",
    "norm_t1 = tf.norm(t1, ord=2, axis=1).numpy()\n",
    "print(norm_t1, end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partir, apilar y concatenar tensores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T22:06:25.487368Z",
     "start_time": "2021-03-14T22:06:25.481386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datos a trabajar\n",
    "# =======================================\n",
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((6,))\n",
    "print(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T22:06:33.850602Z",
     "start_time": "2021-03-14T22:06:33.844607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Partiendo el tensor en un numero determinado de piezas\n",
    "# ======================================================\n",
    "t_splits = tf.split(t, num_or_size_splits = 3)\n",
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T22:06:35.965275Z",
     "start_time": "2021-03-14T22:06:35.957278Z"
    }
   },
   "outputs": [],
   "source": [
    "# Partiendo el tensor segun los tamaños definidos\n",
    "# ======================================================\n",
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((5,))\n",
    "print(t.numpy())\n",
    "t_splits = tf.split(t, num_or_size_splits=[3, 2])\n",
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T22:13:26.767924Z",
     "start_time": "2021-03-14T22:13:26.759935Z"
    }
   },
   "outputs": [],
   "source": [
    "print(matriz_tf.numpy())\n",
    "# m_splits = tf.split(t, num_or_size_splits = 0, axis = 1)\n",
    "matriz_n = tf.reshape(matriz_tf, shape = (8,))\n",
    "print(matriz_n.numpy())\n",
    "m_splits = tf.split(matriz_n, num_or_size_splits = 2)\n",
    "[item.numpy() for item in m_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T22:14:57.330293Z",
     "start_time": "2021-03-14T22:14:57.323313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenando tensores\n",
    "# =========================================\n",
    "A = tf.ones((3,))\n",
    "print(A, end ='\\n'*2)\n",
    "\n",
    "B = tf.zeros((2,))\n",
    "print(B, end ='\\n'*2)\n",
    "\n",
    "C = tf.concat([A, B], axis=0)\n",
    "print(C.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T22:22:00.074165Z",
     "start_time": "2021-03-14T22:22:00.067186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apilando tensores\n",
    "# =========================================\n",
    "A = tf.ones((3,))\n",
    "print(A, end ='\\n'*2)\n",
    "B = tf.zeros((3,))\n",
    "print(B, end ='\\n'*2)\n",
    "S = tf.stack([A, B], axis=1)\n",
    "print(S.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas funciones y herramientas en:\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"burk\">\n",
    "EJERCICIOS</div><i class=\"fa fa-lightbulb-o \"></i>\n",
    "\n",
    "1. Cree dos tensores de dimensiones (4, 6), de numeros aleatorios provenientes de una distribucion normal estandar con promedio 0.0 y dsv 1.0. Imprimalos.\n",
    "2. Multiplique los anteriores tensores de las dos formas vistas, element-wise y producto matricial, realizando las dos transposiciones vistas. \n",
    "3. Calcule los promedios, desviaciones estandar y suma de sus elementos para los dos tensores.\n",
    "4. Redimensione los tensores para que sean ahora de rango 1.\n",
    "5. Calcule el coseno de los elementos de  los tensores (revise la documentacion).\n",
    "6. Cree un tensor de rango 1 con 1001 elementos, empezando con el 0 y hasta el 30.\n",
    "7. Realice un for sobre los elementos del tensor e imprimalos.\n",
    "8. Realice el calculo de los factoriales de los numero del 1 al 30 usando el tensor del punto 6. Imprima el resultado como un DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:08:27.899080Z",
     "start_time": "2021-03-14T23:08:27.880131Z"
    }
   },
   "source": [
    "# Creación de *pipelines* de entrada con tf.data: la API de conjunto de datos de TensorFlow\n",
    "\n",
    "Cuando entrenamos un modelo NN profundo, generalmente entrenamos el modelo de forma incremental utilizando un algoritmo de optimización iterativo como el descenso de gradiente estocástico, como hemos visto en clases anteriores.\n",
    "\n",
    "La API de Keras es un contenedor de TensorFlow para crear modelos NN. La API de Keras proporciona un método, `.fit ()`, para entrenar los modelos. En los casos en que el conjunto de datos de entrenamiento es bastante pequeño y se puede cargar como un tensor en la memoria, los modelos de TensorFlow (que se compilan con la API de Keras) pueden usar este tensor directamente a través de su método .fit () para el entrenamiento. Sin embargo, en casos de uso típicos, cuando el conjunto de datos es demasiado grande para caber en la memoria de la computadora, necesitaremos cargar los datos del dispositivo de almacenamiento principal (por ejemplo, el disco duro o la unidad de estado sólido) en trozos, es decir, lote por lote. \n",
    "\n",
    "Además, es posible que necesitemos construir un *pipeline* de procesamiento de datos para aplicar ciertas transformaciones y pasos de preprocesamiento a nuestros datos, como el centrado medio, el escalado o la adición de ruido para aumentar el procedimiento de entrenamiento y evitar el sobreajuste.\n",
    "\n",
    "Aplicar las funciones de preprocesamiento manualmente cada vez puede resultar bastante engorroso. Afortunadamente, TensorFlow proporciona una clase especial para construir *pipelines* de preprocesamiento eficientes y convenientes. En esta parte, veremos una descripción general de los diferentes métodos para construir un conjunto de datos de TensorFlow, incluidas las transformaciones del conjunto de datos y los pasos de preprocesamiento comunes.\n",
    "\n",
    "## Creando un Dataset de TensorFlow desde tensores existentes\n",
    "\n",
    "Si los datos ya existen en forma de un objeto tensor, una lista de Python o una matriz NumPy, podemos crear fácilmente un conjunto de datos usando la función `tf.data.Dataset.from_tensor_ slices()`. Esta función devuelve un objeto de la clase Dataset, que podemos usar para iterar a través de los elementos individuales en el conjunto de datos de entrada:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:13:16.870380Z",
     "start_time": "2021-03-15T22:13:16.835474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo con listas\n",
    "# ======================================================\n",
    "a = [1.2, 3.4, 7.5, 4.1, 5.0, 1.0]\n",
    "ds = tf.data.Dataset.from_tensor_slices(a)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:13:26.092955Z",
     "start_time": "2021-03-15T22:13:25.964626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4, shape=(), dtype=float32)\n",
      "tf.Tensor(7.5, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for item in ds:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos crear lotes a partir de este conjunto de datos, con un tamaño de lote deseado de 3, podemos hacerlo de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:15:02.763470Z",
     "start_time": "2021-03-15T22:15:02.734549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1: [1.2 3.4 7.5]\n",
      "batch 2: [4.1 5.  1. ]\n"
     ]
    }
   ],
   "source": [
    "# Creando lotes de 3 elementos cada uno\n",
    "# ===================================================\n",
    "ds_batch = ds.batch(3)\n",
    "for i, elem in enumerate(ds_batch, 1):\n",
    "    print(f'batch {i}:', elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto creará dos lotes a partir de este conjunto de datos, donde los primeros tres elementos van al lote n° 1 y los elementos restantes al lote n° 2. El método `.batch()` tiene un argumento opcional, `drop_remainder`, que es útil para los casos en los que el número de elementos en el tensor no es divisible por el tamaño de lote deseado. El valor predeterminado de `drop_remainder` es `False`.\n",
    "\n",
    "## Combinar dos tensores en un Dataset\n",
    "\n",
    "A menudo, podemos tener los datos en dos (o posiblemente más) tensores. Por ejemplo, podríamos tener un tensor para características y un tensor para etiquetas. En tales casos, necesitamos construir un conjunto de datos que combine estos tensores juntos, lo que nos permitirá recuperar los elementos de estos tensores en tuplas.\n",
    "\n",
    "Suponga que tenemos dos tensores, t_x y t_y. El tensor t_x contiene nuestros valores de características, cada uno de tamaño 3, y t_y almacena las etiquetas de clase. Para este ejemplo, primero creamos estos dos tensores de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:17:44.891030Z",
     "start_time": "2021-03-15T22:17:44.880059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]\n",
      " [0.976 0.435 0.66 ]\n",
      " [0.605 0.637 0.614]], shape=(4, 3), dtype=float32)\n",
      "tf.Tensor([0 1 2 3], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Datos de ejemplo\n",
    "# ============================================\n",
    "tf.random.set_seed(1)\n",
    "t_x = tf.random.uniform([4, 3], dtype=tf.float32)\n",
    "t_y = tf.range(4)\n",
    "print(t_x)\n",
    "print(t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:17:47.301733Z",
     "start_time": "2021-03-15T22:17:47.267830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.165 0.901 0.631]  y: 0\n",
      "x: [0.435 0.292 0.643]  y: 1\n",
      "x: [0.976 0.435 0.66 ]  y: 2\n",
      "x: [0.605 0.637 0.614]  y: 3\n"
     ]
    }
   ],
   "source": [
    "# Uniendo los dos tensores en un Dataset\n",
    "# ============================================\n",
    "ds_x = tf.data.Dataset.from_tensor_slices(t_x)\n",
    "ds_y = tf.data.Dataset.from_tensor_slices(t_y)\n",
    "\n",
    "ds_joint = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "\n",
    "for example in ds_joint:\n",
    "    print('x:', example[0].numpy(),' y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:18:51.213779Z",
     "start_time": "2021-03-15T22:18:51.184867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.165 0.901 0.631]  y: 0\n",
      "x: [0.435 0.292 0.643]  y: 1\n",
      "x: [0.976 0.435 0.66 ]  y: 2\n",
      "x: [0.605 0.637 0.614]  y: 3\n"
     ]
    }
   ],
   "source": [
    "ds_joint = tf.data.Dataset.from_tensor_slices((t_x, t_y))\n",
    "for example in ds_joint:\n",
    "    #print(example)\n",
    "    print('x:', example[0].numpy(), ' y:', example[1].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:19:26.314247Z",
     "start_time": "2021-03-15T22:19:26.128425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: [-0.67   0.803  0.262]  y: 0\n",
      " x: [-0.131 -0.416  0.285]  y: 1\n",
      " x: [ 0.952 -0.13   0.32 ]  y: 2\n",
      " x: [0.21  0.273 0.229]  y: 3\n"
     ]
    }
   ],
   "source": [
    "# Operacion sobre el dataset generado\n",
    "# ====================================================\n",
    "ds_trans = ds_joint.map(lambda x, y: (x*2-1.0, y))\n",
    "for example in ds_trans: \n",
    "    print(' x:', example[0].numpy(), ' y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mezclar, agrupar y repetir\n",
    "\n",
    "Para entrenar un modelo NN usando la optimización de descenso de gradiente estocástico, es importante alimentar los datos de entrenamiento como lotes mezclados aleatoriamente. Ya hemos visto arriba como crear lotes llamando al método `.batch()` de un objeto de conjunto de datos. Ahora, además de crear lotes, vamos a mezclar y reiterar sobre los conjuntos de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:23:25.068977Z",
     "start_time": "2021-03-15T22:23:25.035124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: [0.976 0.435 0.66 ]  y: 2\n",
      " x: [0.435 0.292 0.643]  y: 1\n",
      " x: [0.165 0.901 0.631]  y: 0\n",
      " x: [0.605 0.637 0.614]  y: 3\n"
     ]
    }
   ],
   "source": [
    "# Mezclando los elementos de un tensor\n",
    "# ===================================================\n",
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.shuffle(buffer_size = len(t_x))\n",
    "for example in ds:\n",
    "    print(' x:', example[0].numpy(), ' y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:21:23.036313Z",
     "start_time": "2021-03-15T22:21:23.025308Z"
    }
   },
   "source": [
    "donde las filas se barajan sin perder la correspondencia uno a uno entre las entradas en x e y. El método `.shuffle()` requiere un argumento llamado `buffer_size`, que determina cuántos elementos del conjunto de datos se agrupan antes de barajar. Los elementos del búfer se recuperan aleatoriamente y su lugar en el búfer se asigna a los siguientes elementos del conjunto de datos original (sin mezclar). Por lo tanto, si elegimos un tamaño de búfer pequeño, es posible que no mezclemos perfectamente el conjunto de datos.\n",
    "\n",
    "Si el conjunto de datos es pequeño, la elección de un tamaño de búfer relativamente pequeño puede afectar negativamente el rendimiento predictivo del NN, ya que es posible que el conjunto de datos no esté completamente aleatorizado. En la práctica, sin embargo, por lo general no tiene un efecto notable cuando se trabaja con conjuntos de datos relativamente grandes, lo cual es común en el aprendizaje profundo.\n",
    "\n",
    "Alternativamente, para asegurar una aleatorización completa durante cada época, simplemente podemos elegir un tamaño de búfer que sea igual al número de ejemplos de entrenamiento, como en el código anterior (`buffer_size = len(t_x)`).\n",
    "\n",
    " Ahora, creemos lotes a partir del conjunto de datos ds_joint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:33:34.017208Z",
     "start_time": "2021-03-15T22:33:33.991324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 3), (None,)), types: (tf.float32, tf.int32)>\n",
      "Batch-x:\n",
      " [[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]\n",
      " [0.976 0.435 0.66 ]]\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.batch(batch_size = 3, drop_remainder = False)\n",
    "print(ds)\n",
    "batch_x, batch_y = next(iter(ds))\n",
    "print('Batch-x:\\n', batch_x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:33:28.867985Z",
     "start_time": "2021-03-15T22:33:28.863996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-y:  [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print('Batch-y: ', batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, al entrenar un modelo para múltiples épocas, necesitamos mezclar e iterar sobre el conjunto de datos por el número deseado de épocas. Entonces, repitamos el conjunto de datos por lotes dos veces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:40:59.474952Z",
     "start_time": "2021-03-15T22:40:59.448031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]\n",
      " [0.976 0.435 0.66 ]] [0 1 2]\n",
      "\n",
      "1 [[0.605 0.637 0.614]] [3]\n",
      "\n",
      "2 [[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]\n",
      " [0.976 0.435 0.66 ]] [0 1 2]\n",
      "\n",
      "3 [[0.605 0.637 0.614]] [3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.batch(3).repeat(count = 2)\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.numpy(), batch_y.numpy(), end = '\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto da como resultado dos copias de cada lote. Si cambiamos el orden de estas dos operaciones, es decir, primero lote y luego repetimos, los resultados serán diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T22:40:57.685204Z",
     "start_time": "2021-03-15T22:40:57.670245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]\n",
      " [0.976 0.435 0.66 ]] [0 1 2]\n",
      "\n",
      "1 [[0.605 0.637 0.614]\n",
      " [0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]] [3 0 1]\n",
      "\n",
      "2 [[0.976 0.435 0.66 ]\n",
      " [0.605 0.637 0.614]] [2 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.repeat(count=2).batch(3)\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.numpy(), batch_y.numpy(), end = '\\n'*2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
